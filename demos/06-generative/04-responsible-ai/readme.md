# Implement responsible generative AI in AI Studio

## Links & Resources

[Azure AI Content Safety documentation](https://learn.microsoft.com/en-us/azure/ai-services/content-safety/overview)

[Azure Content Safety Studio](https://contentsafety.cognitive.azure.com/)

[Azure Content Safety GitHub Samples](https://github.com/Azure-Samples/AzureAIContentSafety)

[Groundedness detection](https://learn.microsoft.com/en-us/azure/ai-services/content-safety/concepts/groundedness)

[Prompt Shields](https://learn.microsoft.com/en-us/azure/ai-services/content-safety/concepts/jailbreak-detection)

[Custom categories](https://learn.microsoft.com/en-us/azure/ai-services/content-safety/concepts/custom-categories?tabs=standard)

[Protected material detection](https://learn.microsoft.com/en-us/azure/ai-services/content-safety/concepts/protected-material?tabs=text)

## Demos

- Explain Azure Content Safety Studio

  - Mention that an explicit `Content Safety Instance` and a `Connection` has been created

  - Show how to moderate images. Take the images from [assets](assets/)

- Run `moderate-text.py`to moderate a give test

## Labs

[Operationalize AI responsibly with Azure AI Foundry](https://learn.microsoft.com/en-us/training/paths/operationalize-ai-responsibly/)
